{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EBAC - Regressão II - regressão múltipla\n",
    "\n",
    "## Tarefa I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Previsão de renda II\n",
    "\n",
    "Vamos continuar trabalhando com a base 'previsao_de_renda.csv', que é a base do seu próximo projeto. Vamos usar os recursos que vimos até aqui nesta base.\n",
    "\n",
    "|variavel|descrição|\n",
    "|-|-|\n",
    "|data_ref                | Data de referência de coleta das variáveis |\n",
    "|index                   | Código de identificação do cliente|\n",
    "|sexo                    | Sexo do cliente|\n",
    "|posse_de_veiculo        | Indica se o cliente possui veículo|\n",
    "|posse_de_imovel         | Indica se o cliente possui imóvel|\n",
    "|qtd_filhos              | Quantidade de filhos do cliente|\n",
    "|tipo_renda              | Tipo de renda do cliente|\n",
    "|educacao                | Grau de instrução do cliente|\n",
    "|estado_civil            | Estado civil do cliente|\n",
    "|tipo_residencia         | Tipo de residência do cliente (própria, alugada etc)|\n",
    "|idade                   | Idade do cliente|\n",
    "|tempo_emprego           | Tempo no emprego atual|\n",
    "|qt_pessoas_residencia   | Quantidade de pessoas que moram na residência|\n",
    "|renda                   | Renda em reais|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('previsao_de_renda.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15000 entries, 0 to 14999\n",
      "Data columns (total 16 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Unnamed: 0             15000 non-null  int64  \n",
      " 1   data_ref               15000 non-null  object \n",
      " 2   index                  15000 non-null  int64  \n",
      " 3   sexo                   15000 non-null  object \n",
      " 4   posse_de_veiculo       15000 non-null  bool   \n",
      " 5   posse_de_imovel        15000 non-null  bool   \n",
      " 6   qtd_filhos             15000 non-null  int64  \n",
      " 7   tipo_renda             15000 non-null  object \n",
      " 8   educacao               15000 non-null  object \n",
      " 9   estado_civil           15000 non-null  object \n",
      " 10  tipo_residencia        15000 non-null  object \n",
      " 11  idade                  15000 non-null  int64  \n",
      " 12  tempo_emprego          12466 non-null  float64\n",
      " 13  qt_pessoas_residencia  15000 non-null  float64\n",
      " 14  mau                    15000 non-null  bool   \n",
      " 15  renda                  15000 non-null  float64\n",
      "dtypes: bool(3), float64(3), int64(4), object(6)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Separe a base em treinamento e teste (25% para teste, 75% para treinamento).\n",
    "2. Rode uma regularização *ridge* com alpha = [0, 0.001, 0.005, 0.01, 0.05, 0.1] e avalie o $R^2$ na base de testes. Qual o melhor modelo?\n",
    "3. Faça o mesmo que no passo 2, com uma regressão *LASSO*. Qual método chega a um melhor resultado?\n",
    "4. Rode um modelo *stepwise*. Avalie o $R^2$ na vase de testes. Qual o melhor resultado?\n",
    "5. Compare os parâmetros e avalie eventuais diferenças. Qual modelo você acha o melhor de todos?\n",
    "6. Partindo dos modelos que você ajustou, tente melhorar o $R^2$ na base de testes. Use a criatividade, veja se consegue inserir alguma transformação ou combinação de variáveis.\n",
    "7. Ajuste uma árvore de regressão e veja se consegue um $R^2$ melhor com ela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12466 entries, 0 to 12465\n",
      "Data columns (total 30 columns):\n",
      " #   Column                         Non-Null Count  Dtype         \n",
      "---  ------                         --------------  -----         \n",
      " 0   level_0                        12466 non-null  int64         \n",
      " 1   data_ref                       12466 non-null  datetime64[ns]\n",
      " 2   index                          12466 non-null  int64         \n",
      " 3   sexo                           12466 non-null  int64         \n",
      " 4   posse_de_veiculo               12466 non-null  int32         \n",
      " 5   posse_de_imovel                12466 non-null  int32         \n",
      " 6   qtd_filhos                     12466 non-null  int64         \n",
      " 7   idade                          12466 non-null  int64         \n",
      " 8   tempo_emprego                  12466 non-null  float64       \n",
      " 9   qt_pessoas_residencia          12466 non-null  float64       \n",
      " 10  mau                            12466 non-null  int32         \n",
      " 11  renda                          12466 non-null  float64       \n",
      " 12  tipo_residencia_Casa           12466 non-null  uint8         \n",
      " 13  tipo_residencia_Com os pais    12466 non-null  uint8         \n",
      " 14  tipo_residencia_Comunitário    12466 non-null  uint8         \n",
      " 15  tipo_residencia_Estúdio        12466 non-null  uint8         \n",
      " 16  tipo_residencia_Governamental  12466 non-null  uint8         \n",
      " 17  estado_civil_Separado          12466 non-null  uint8         \n",
      " 18  estado_civil_Solteiro          12466 non-null  uint8         \n",
      " 19  estado_civil_União             12466 non-null  uint8         \n",
      " 20  estado_civil_Viúvo             12466 non-null  uint8         \n",
      " 21  educacao_Pós graduação         12466 non-null  uint8         \n",
      " 22  educacao_Secundário            12466 non-null  uint8         \n",
      " 23  educacao_Superior completo     12466 non-null  uint8         \n",
      " 24  educacao_Superior incompleto   12466 non-null  uint8         \n",
      " 25  tipo_renda_Bolsista            12466 non-null  uint8         \n",
      " 26  tipo_renda_Empresário          12466 non-null  uint8         \n",
      " 27  tipo_renda_Pensionista         12466 non-null  uint8         \n",
      " 28  tipo_renda_Servidor público    12466 non-null  uint8         \n",
      " 29  log_renda                      12466 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(4), int32(3), int64(5), uint8(17)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "df.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "df['sexo'] = df['sexo'].map({'F':0,'M':1})\n",
    "df['posse_de_veiculo'] = df['posse_de_veiculo'].astype(int)\n",
    "df['posse_de_imovel'] = df['posse_de_imovel'].astype(int)\n",
    "df['mau'] = df['mau'].astype(int)\n",
    "df['data_ref'] = pd.to_datetime(df['data_ref']) \n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(inplace= True)\n",
    "df_clear = pd.get_dummies(df,columns=['tipo_residencia','estado_civil','educacao','tipo_renda'],drop_first=True)\n",
    "df_clear['log_renda'] = np.log(df_clear['renda'])\n",
    "df_clear.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_clear.drop(columns=['data_ref', 'index', 'renda','log_renda'])\n",
    "y = df_clear['log_renda']\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Ridge alpha: 0.1, R^2: 0.23387132527927568\n",
      "Ridge coefficients: [-1.50065200e-06  4.84023315e-01 -3.08822164e-03  1.05938045e-01\n",
      "  1.19014245e-01  3.94561474e-03  4.92750746e-02 -1.06313005e-01\n",
      " -2.25980652e-03  7.62739733e-03 -7.27561656e-02 -3.03729621e-02\n",
      " -5.11636386e-02 -3.96563411e-02 -1.52958797e-01 -9.63821076e-02\n",
      " -1.71127020e-02 -1.28250667e-01  4.54617807e-01 -8.78491961e-03\n",
      "  8.51644716e-02 -2.61585789e-02 -1.84249000e-02  1.67022686e-01\n",
      "  3.77972226e-01  8.54747171e-02]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge,Lasso\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "alphas = [0, 0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "ridge_scores = {}\n",
    "\n",
    "for alpha in alphas:\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "    ridge.fit(X_train, y_train)\n",
    "    y_pred = ridge.predict(X_test)\n",
    "    ridge_scores[alpha] = r2_score(y_test, y_pred)\n",
    "\n",
    "best_ridge_alpha = max(ridge_scores, key=ridge_scores.get)\n",
    "best_ridge_score = ridge_scores[best_ridge_alpha]\n",
    "best_ridge_model = Ridge(alpha=best_ridge_alpha).fit(X_train, y_train)\n",
    "print(f\"Best Ridge alpha: {best_ridge_alpha}, R^2: {best_ridge_score}\")\n",
    "print(f\"Ridge coefficients: {best_ridge_model.coef_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13716\\2932569161.py:5: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  lasso.fit(X_train, y_train)\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.281e+03, tolerance: 6.032e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13716\\2932569161.py:11: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  best_lasso_model = Lasso(alpha=best_lasso_alpha, max_iter=10000).fit(X_train, y_train)\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LASSO alpha: 0, R^2: 0.2338600853220969\n",
      "LASSO coefficients: [-1.50040080e-06  4.84057686e-01 -3.10887786e-03  1.05935317e-01\n",
      "  1.24031774e-01  3.94599598e-03  4.92749410e-02 -1.11326716e-01\n",
      " -2.29804674e-03  7.48528529e-03 -7.29079389e-02 -3.05214498e-02\n",
      " -5.13831764e-02 -3.97947921e-02 -1.57997013e-01 -1.01386089e-01\n",
      " -1.71192680e-02 -1.33310854e-01  4.58172483e-01 -8.07757348e-03\n",
      "  8.58732058e-02 -2.54580525e-02 -1.90338818e-02  1.67026481e-01\n",
      "  3.83410853e-01  8.54999400e-02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.281e+03, tolerance: 6.032e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "lasso_scores = {}\n",
    "\n",
    "for alpha in alphas:\n",
    "    lasso = Lasso(alpha=alpha, max_iter=10000)  # Aumentar o número de iterações para garantir a convergência\n",
    "    lasso.fit(X_train, y_train)\n",
    "    y_pred = lasso.predict(X_test)\n",
    "    lasso_scores[alpha] = r2_score(y_test, y_pred)\n",
    "\n",
    "best_lasso_alpha = max(lasso_scores, key=lasso_scores.get)\n",
    "best_lasso_score = lasso_scores[best_lasso_alpha]\n",
    "best_lasso_model = Lasso(alpha=best_lasso_alpha, max_iter=10000).fit(X_train, y_train)\n",
    "print(f\"Best LASSO alpha: {best_lasso_alpha}, R^2: {best_lasso_score}\")\n",
    "print(f\"LASSO coefficients: {best_lasso_model.coef_}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores recursos selecionados: ['tempo_emprego', 'sexo', 'tipo_renda_Empresário', 'idade', 'educacao_Superior completo', 'tipo_renda_Servidor público', 'tipo_residencia_Casa', 'educacao_Pós graduação', 'qt_pessoas_residencia', 'estado_civil_Solteiro', 'tipo_residencia_Comunitário', 'qtd_filhos', 'estado_civil_União', 'level_0', 'tipo_renda_Pensionista', 'educacao_Secundário', 'mau']\n",
      "Melhor R^2: 0.23685615438531893\n",
      "Stepwise model R^2: 0.23685615438531893\n",
      "Stepwise coefficients: const                          7.163726\n",
      "tempo_emprego                  0.049057\n",
      "sexo                           0.482741\n",
      "tipo_renda_Empresário          0.167135\n",
      "idade                          0.004416\n",
      "educacao_Superior completo     0.116355\n",
      "tipo_renda_Servidor público    0.085422\n",
      "tipo_residencia_Casa           0.090099\n",
      "educacao_Pós graduação         0.518324\n",
      "qt_pessoas_residencia          0.036590\n",
      "estado_civil_Solteiro          0.049774\n",
      "tipo_residencia_Comunitário    0.039530\n",
      "qtd_filhos                    -0.020499\n",
      "estado_civil_União            -0.024927\n",
      "level_0                       -0.000001\n",
      "tipo_renda_Pensionista         0.376376\n",
      "educacao_Secundário            0.020562\n",
      "mau                           -0.008760\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def forward_stepwise_selection(X_train, y_train, X_test, y_test):\n",
    "    remaining_features = list(X_train.columns)\n",
    "    current_features = []\n",
    "    best_r2 = 0.0\n",
    "\n",
    "    while remaining_features:\n",
    "        r2_with_new_feature = []\n",
    "\n",
    "        for feature in remaining_features:\n",
    "            features_to_use = current_features + [feature]\n",
    "            X_train_sm = sm.add_constant(X_train[features_to_use])\n",
    "            X_test_sm = sm.add_constant(X_test[features_to_use])\n",
    "            model = sm.OLS(y_train, X_train_sm).fit()\n",
    "            predictions = model.predict(X_test_sm)\n",
    "            r2 = r2_score(y_test, predictions)\n",
    "            r2_with_new_feature.append((r2, feature))\n",
    "\n",
    "        r2_with_new_feature.sort(reverse=True)\n",
    "        best_r2_new, best_new_feature = r2_with_new_feature[0]\n",
    "\n",
    "        if best_r2_new > best_r2:\n",
    "            remaining_features.remove(best_new_feature)\n",
    "            current_features.append(best_new_feature)\n",
    "            best_r2 = best_r2_new\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return current_features, best_r2\n",
    "\n",
    "selected_features, best_r2 = forward_stepwise_selection(X_train, y_train, X_test, y_test)\n",
    "print(\"Melhores recursos selecionados:\", selected_features)\n",
    "print(\"Melhor R^2:\", best_r2)\n",
    "\n",
    "\n",
    "X_train_selected = sm.add_constant(X_train[selected_features])\n",
    "X_test_selected = sm.add_constant(X_test[selected_features])\n",
    "stepwise_model = sm.OLS(y_train, X_train_selected).fit()\n",
    "y_pred = stepwise_model.predict(X_test_selected)\n",
    "stepwise_score = r2_score(y_test, y_pred)\n",
    "print(f\"Stepwise model R^2: {stepwise_score}\")\n",
    "print(f\"Stepwise coefficients: {stepwise_model.params}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge coefficients: [-1.50065200e-06  4.84023315e-01 -3.08822164e-03  1.05938045e-01\n",
      "  1.19014245e-01  3.94561474e-03  4.92750746e-02 -1.06313005e-01\n",
      " -2.25980652e-03  7.62739733e-03 -7.27561656e-02 -3.03729621e-02\n",
      " -5.11636386e-02 -3.96563411e-02 -1.52958797e-01 -9.63821076e-02\n",
      " -1.71127020e-02 -1.28250667e-01  4.54617807e-01 -8.78491961e-03\n",
      "  8.51644716e-02 -2.61585789e-02 -1.84249000e-02  1.67022686e-01\n",
      "  3.77972226e-01  8.54747171e-02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13716\\3585891120.py:6: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  best_lasso_model = Lasso(alpha=best_lasso_alpha).fit(X_train, y_train)\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LASSO coefficients: [-1.50681107e-06  4.84091213e-01 -3.12287397e-03  1.05946785e-01\n",
      "  9.08848541e-02  3.94249470e-03  4.92788896e-02 -7.82537957e-02\n",
      " -3.22236041e-03  7.41750576e-03 -7.29616225e-02 -3.05659594e-02\n",
      " -5.14066673e-02 -3.98194988e-02 -1.24916257e-01 -6.85839382e-02\n",
      " -1.70404121e-02 -1.00214415e-01  4.58239223e-01 -8.06704706e-03\n",
      "  8.58870255e-02 -2.54072506e-02 -1.90894515e-02  1.67083275e-01\n",
      "  3.84411436e-01  8.54863884e-02]\n",
      "Stepwise coefficients: const                          7.163726\n",
      "tempo_emprego                  0.049057\n",
      "sexo                           0.482741\n",
      "tipo_renda_Empresário          0.167135\n",
      "idade                          0.004416\n",
      "educacao_Superior completo     0.116355\n",
      "tipo_renda_Servidor público    0.085422\n",
      "tipo_residencia_Casa           0.090099\n",
      "educacao_Pós graduação         0.518324\n",
      "qt_pessoas_residencia          0.036590\n",
      "estado_civil_Solteiro          0.049774\n",
      "tipo_residencia_Comunitário    0.039530\n",
      "qtd_filhos                    -0.020499\n",
      "estado_civil_União            -0.024927\n",
      "level_0                       -0.000001\n",
      "tipo_renda_Pensionista         0.376376\n",
      "educacao_Secundário            0.020562\n",
      "mau                           -0.008760\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.281e+03, tolerance: 6.032e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# Ridge com melhor alpha\n",
    "best_ridge_model = Ridge(alpha=best_ridge_alpha).fit(X_train, y_train)\n",
    "print(f\"Ridge coefficients: {best_ridge_model.coef_}\")\n",
    "\n",
    "# LASSO com melhor alpha\n",
    "best_lasso_model = Lasso(alpha=best_lasso_alpha).fit(X_train, y_train)\n",
    "print(f\"LASSO coefficients: {best_lasso_model.coef_}\")\n",
    "\n",
    "# Stepwise model\n",
    "print(f\"Stepwise coefficients: {stepwise_model.params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Decision Tree parameters: {'max_depth': 5, 'max_features': None, 'min_samples_leaf': 2, 'min_samples_split': 10}\n",
      "Best Decision Tree R^2: 0.2093347228505279\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Definir os parâmetros para a busca em grade\n",
    "param_grid = {\n",
    "    'max_depth': [None, 5, 10, 15, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': [None, 'auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Ajustar a árvore de regressão usando GridSearchCV\n",
    "tree = DecisionTreeRegressor(random_state=42)\n",
    "grid_search = GridSearchCV(estimator=tree, param_grid=param_grid, cv=5, n_jobs=-1, scoring='r2')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Prever e calcular o R^2 com os melhores parâmetros encontrados\n",
    "best_tree = grid_search.best_estimator_\n",
    "y_pred = best_tree.predict(X_test)\n",
    "best_tree_r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Best Decision Tree parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best Decision Tree R^2: {best_tree_r2}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
